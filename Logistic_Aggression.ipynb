{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Theoretical Questions:**\n"
      ],
      "metadata": {
        "id": "uHxRCaZsdv6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        " - **Logistic Regression** is a statistical model used for binary classification, which means it predicts a categorical outcome that can take on one of two values (e.g., yes/no, true/false, 0/1). It's often used when you want to model the probability of a certain event occurring.\n",
        " - The key difference lies in the type of outcome variable they predict. Linear Regression is for continuous outcomes, while Logistic Regression is for categorical outcomes [1]. Logistic Regression uses a sigmoid function to transform the output of the linear equation into a probability between 0 and 1, which is then used to classify the outcome."
      ],
      "metadata": {
        "id": "Ce3gH06Sd7TY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. What is the mathematical equation of Logistic Regression?\n",
        " - Logistic Regression is used for binary classification problems, where the outcome can be either 0 or 1. It is based on the sigmoid function, which maps any real number into a value between 0 and 1.\n",
        "\n",
        "The mathematical equation for Logistic Regression is:\n",
        "\n",
        "ùëù\n",
        "(\n",
        "ùë¶\n",
        "=\n",
        "1\n",
        "‚à£\n",
        "ùëã\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "ùëí\n",
        "‚àí\n",
        "(\n",
        "ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ\n",
        "1\n",
        "ùëã\n",
        "1\n",
        "+\n",
        "ùõΩ\n",
        "2\n",
        "ùëã\n",
        "2\n",
        "+\n",
        ".\n",
        ".\n",
        ".\n",
        "+\n",
        "ùõΩ\n",
        "ùëõ\n",
        "ùëã\n",
        "ùëõ\n",
        ")\n",
        "\n",
        "Where:\n",
        "\n",
        " - ùëù\n",
        "(\n",
        "ùë¶\n",
        "=\n",
        "1\n",
        "‚à£\n",
        "ùëã\n",
        ")\n",
        " is the probability that the outcome is 1 given the input\n",
        "ùëã\n",
        ".\n",
        "\n",
        " - ùõΩ\n",
        "0\n",
        " is the intercept.\n",
        "\n",
        " - ùõΩ\n",
        "1\n",
        ",\n",
        "ùõΩ\n",
        "2\n",
        ",\n",
        ".\n",
        ".\n",
        ".\n",
        ",\n",
        "ùõΩ\n",
        "ùëõ\n",
        " are the coefficients of the independent variables\n",
        "ùëã\n",
        "1\n",
        ",\n",
        "ùëã\n",
        "2\n",
        ",\n",
        ".\n",
        ".\n",
        ".\n",
        ",\n",
        "ùëã\n",
        "ùëõ\n",
        ".\n",
        "\n",
        " - ùëí\n",
        " is Euler's number (approximately 2.718).\n",
        "\n",
        " - The term inside the exponent\n",
        "\n",
        "ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ\n",
        "1\n",
        "ùëã\n",
        "1\n",
        "+\n",
        "ùõΩ\n",
        "2\n",
        "ùëã\n",
        "2\n",
        "+\n",
        ".\n",
        ".\n",
        ".\n",
        "+\n",
        "ùõΩ\n",
        "ùëõ\n",
        "ùëã\n",
        "ùëõ\n",
        " represents a linear combination of the input features."
      ],
      "metadata": {
        "id": "nHSawqIweXbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Why do we use the Sigmoid function in Logistic Regression?\n",
        " - The Sigmoid function is crucial in Logistic Regression because it transforms linear outputs into probabilities, making it ideal for classification tasks. Here‚Äôs why:\n",
        "- **Probability Output:** The Sigmoid function maps any input value to a range between 0 and 1, which can be interpreted as the probability of belonging to a certain class.\n",
        "- **Non-Linearity:** Even though Logistic Regression uses a linear model, the Sigmoid function introduces non-linearity, allowing for more flexibility in decision boundaries.\n",
        "- **Thresholding for Classification:** Once we obtain probability values, we can set a threshold (commonly 0.5) to decide the class label‚Äîvalues above the threshold belong to one category, while values below belong to another.\n",
        "- **Gradient-Based Optimization:** Since the Sigmoid function is differentiable, it enables optimization techniques like gradient descent to efficiently update model parameters during training.\n"
      ],
      "metadata": {
        "id": "J9Kh0lrNmbnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. What is the cost function of Logistic Regression?\n",
        " - In Logistic Regression, we use the Log Loss (or Binary Cross-Entropy) as the cost function. Since the Sigmoid function outputs probabilities, we need a cost function that measures how well the predicted probabilities match the actual labels.\n",
        "\n",
        " The formula is:\n",
        "\n",
        "\n",
        "[ J(\\theta) = - \\frac{1}{m} \\sum_{i=1}{(i)} \\log(h_{\\theta}(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_{\\theta}(x^{(i)})) \\right] ]\n",
        "\n",
        "Where:\n",
        "- ( m ) is the number of training examples.\n",
        "- ( y^{(i)} ) is the actual class label (0 or 1).\n",
        "- ( h_{\\theta}(x^{(i)}) ) is the predicted probability from the Sigmoid function.\n",
        "- The logarithm ensures that confident, correct predictions are rewarded while incorrect predictions are penalized heavily.\n"
      ],
      "metadata": {
        "id": "laJNDQNfLomI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. What is Regularization in Logistic Regression? Why is it needed?\n",
        " - **Regularization** in Logistic Regression is a technique used to prevent overfitting by adding a penalty term to the cost function. It ensures that the model learns a generalizable decision boundary rather than memorizing the training data. Here‚Äôs why it‚Äôs important:\n",
        "\n",
        " Why is Regularization Needed?\n",
        "- Overfitting Prevention: Logistic Regression can assign very large weights to some features, making the model too sensitive to noise. Regularization discourages excessively large weights and improves generalization.\n",
        "- Feature Selection: In high-dimensional datasets, regularization helps reduce the impact of irrelevant features, leading to a more efficient model.\n",
        "- Stable Optimization: Large coefficients can cause numerical instability during training, and regularization ensures a smooth learning process.\n"
      ],
      "metadata": {
        "id": "6TSngbzYMUsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
        " - Ridge Regression (L2 Regularization)\n",
        "    - Penalty: Adds the sum of the squared coefficients to the cost function.\n",
        "    - Effect: Shrinks coefficients but doesn‚Äôt set them to zero. All features remain in the model.\n",
        "    - Use Case: Ideal when all predictors are relevant but need to be reduced in magnitude.\n",
        "  \n",
        " - Lasso Regression (L1 Regularization)\n",
        "    - Penalty: Adds the sum of the absolute values of coefficients.\n",
        "    - Effect: Encourages sparsity by forcing some coefficients to become exactly zero, effectively selecting important features.\n",
        "    - Use Case: Great for feature selection, especially when many predictors are irrelevant.\n",
        "\n",
        " -  Elastic Net Regression (Combination of L1 and L2)\n",
        "    - Penalty: A mix of Lasso and Ridge, controlled by an additional parameter.\n",
        "    - Effect: Balances sparsity (Lasso) with coefficient shrinkage (Ridge), handling situations where features are correlated.\n",
        "    - Use Case: Useful when dealing with high-dimensional data with multicollinearity.\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "Y66G2KW0M4ai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. When should we use Elastic Net instead of Lasso or Ridge?\n",
        " - Elastic Net is particularly useful when you have high-dimensional data with correlated features. Here‚Äôs when you should consider using it instead of Lasso or Ridge:\n",
        "- When Lasso Struggles with Multicollinearity: Lasso tends to arbitrarily select one correlated feature and discard the rest, which can lead to unstable results. Elastic Net, by blending L1 and L2 penalties, allows for better feature selection while keeping correlated variables.\n",
        "- When Ridge Keeps Too Many Features: Ridge shrinks coefficients but doesn‚Äôt force any to be zero. If your goal is to perform feature selection while still controlling for multicollinearity, Elastic Net is a good middle ground.\n",
        "- When You Have More Features Than Observations: If your dataset has many predictors (potentially more than samples), Lasso may select too few while Ridge keeps too many. Elastic Net balances these extremes by allowing some sparsity while avoiding excessive elimination.\n",
        "- When You Want a More Flexible Regularization Model: Elastic Net has a tunable parameter ((\\alpha)) that controls the balance between L1 and L2 regularization, giving you more control over the model complexity.\n"
      ],
      "metadata": {
        "id": "U78IsKF-N_lH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. What is the impact of the regularization parameter (Œª) in Logistic Regression?\n",
        " - The regularization parameter ( \\lambda ) plays a crucial role in controlling the complexity of the model in Logistic Regression. Here‚Äôs how it impacts the model:\n",
        "1. **Controls Model Complexity**\n",
        "- A small ( \\lambda ) means less regularization, allowing the model to fit the training data more closely. This can lead to overfitting, where the model captures noise instead of general patterns.\n",
        "- A large ( \\lambda ) increases regularization, penalizing large coefficients and making the model simpler. This can help prevent overfitting but may lead to underfitting, where the model is too constrained to capture important patterns.\n",
        "2. **Affects Feature Weights**\n",
        "- Higher ( \\lambda ) forces the model to reduce the magnitude of the coefficients, leading to a more stable and generalizable solution.\n",
        "- In L1 regularization (Lasso), higher ( \\lambda ) can push some feature coefficients to exactly zero, effectively performing feature selection.\n",
        "- In L2 regularization (Ridge), higher ( \\lambda ) shrinks all coefficients, but none become exactly zero.\n",
        "3. **Impacts Decision Boundaries**\n",
        "- Without regularization (( \\lambda = 0 )), Logistic Regression might find sharp decision boundaries, leading to poor generalization.\n",
        "- With moderate ( \\lambda ), the boundaries become smoother, improving robustness to new data.\n",
        "- Excessive ( \\lambda ) makes the model too rigid, potentially missing important distinctions between classes.\n",
        "Finding the Right ( \\lambda )\n",
        "- Typically, cross-validation is used to tune ( \\lambda ) and find the balance between bias and variance.\n",
        "- A good choice of ( \\lambda ) leads to an optimal trade-off between accuracy and generalization.\n",
        "Would you like to see an example of how different ( \\lambda ) values affect model performance?\n"
      ],
      "metadata": {
        "id": "1sWqpVuaONkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. What are the key assumptions of Logistic Regression?\n",
        " - Logistic Regression relies on several key assumptions to ensure its effectiveness in classification tasks. Unlike linear regression, it does not require the target variable to be continuous, but it does have its own set of requirements:\n",
        "1. **Independent Observation**\n",
        "2. **No Multicollinearity**\n",
        "3. **Linearity in Log-Odds**\n",
        "4. **Large Sample Size**\n",
        "5. **The Dependent Variable is Binary or Multiclass (Categorical)**\n",
        "6. **No Outliers with Extreme Influence**"
      ],
      "metadata": {
        "id": "Ajm6yh01O10m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. What are some alternatives to Logistic Regression for classification tasks?\n",
        " - There are several alternatives to Logistic Regression that can be used for classification tasks, depending on the nature of your data and the problem you're trying to solve. Here are some popular alternatives:\n",
        "1. **Decision Trees**\n",
        "2. **Random Forest**\n",
        "3. **Support Vector Machines (SVM)**\n",
        "4. **K-Nearest Neighbors (KNN)**\n",
        "5. **Na√Øve Bayes**\n",
        "6. **Neural Networks**\n",
        "7. **Gradient Boosting Methods**"
      ],
      "metadata": {
        "id": "XW6QXkNsP2Fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. What are Classification Evaluation Metrics?\n",
        " - Classification evaluation metrics are used to assess the performance of a classification model. They help determine how well the model predicts categorical labels. here are some key matrics:     \n",
        " 1. **Accuracy** - It measures the overall correctness of predictions.\n",
        " 2. **Precision** - It focuses on how many positive predictions were actually correct.\n",
        " 3. **Recall( Sensitivity)** - It measures the ability of the model to correctly identify all relevant cases.\n",
        " 4. **F1 Score** - A balance between precision and recall.\n",
        " 5. **ROC Curve & AUC** - It shows the trade-off between true positive rate and false positive rate. AUC(Area Under the Curve) quantifies this performance.\n",
        " 6. **Confusion Matrix** - A table displaying actual vs. predicted classifications, helping visualize model errors."
      ],
      "metadata": {
        "id": "tZPSYHeTT4cI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12. How does class imbalance affect Logistic Regression?\n",
        " - Class imbalance can significantly impact Logistic Regression, leading to biased predictions and poor model performance. Here‚Äôs how:        \n",
        "**Effects of Class Imbalance:**\n",
        " 1. **Biased Predictions**\n",
        " 2. **Poor Recall for Minority Class**\n",
        " 3. **Misleading Accuracy**\n",
        " 4. **Skewed Probability Estimates**\n"
      ],
      "metadata": {
        "id": "SZbQo8dfpR2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13. What is Hyperparameter Tuning in Logistic Regression?\n",
        " - Hyperparameter tuning in Logistic Regression refers to the process of optimizing parameters that are not learned during training but instead set manually to improve the model‚Äôs performance. These hyperparameters affect how the model learns and generalizes."
      ],
      "metadata": {
        "id": "l9PUXipDrfIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14. What are different solvers in Logistic Regression? Which one should be used?\n",
        " - Logistic Regression in scikit-learn offers several solvers, each optimized for different scenarios. Here‚Äôs a breakdown:   \n",
        "**Common Solvers in Logistic Regression**\n",
        "1. **Liblinear**\n",
        "2. **lbfgs**\n",
        "3. **Newton-cg**\n",
        "4. **sag**\n",
        "5. **saga**\n",
        "\n",
        "**Which Solver Should You Use?**\n",
        " - **For small datasets ‚Üí** `liblinear`\n",
        "\n",
        " - **For large datasets ‚Üí** `sag` or `saga`\n",
        "\n",
        " - **For multiclass classification ‚Üí** `lbfgs` or `newton-cg`\n",
        "\n",
        " - **For sparse data ‚Üí** `saga`\n",
        "\n",
        " - **For L1 regularization (feature selection) ‚Üí** `liblinear` or `saga`"
      ],
      "metadata": {
        "id": "SmzUC8dwry7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15. How is Logistic Regression extended for multiclass classification?\n",
        " - Logistic Regression is naturally designed for binary classification, but it can be extended to multiclass classification using two main approaches:\n",
        "\n",
        "**1. One-vs-Rest (OvR) Approach**\n",
        " - Also known as One-vs-All, this method trains multiple binary classifiers.\n",
        "\n",
        " - For a dataset with K classes, the model trains K separate logistic regression models.\n",
        "\n",
        " - Each model predicts whether a sample belongs to a specific class or not.\n",
        "\n",
        " - The class with the highest probability is chosen as the final prediction.\n",
        "\n",
        "**2. Softmax (Multinomial) Regression**\n",
        " - Instead of training multiple binary classifiers, Softmax Regression extends Logistic Regression to handle multiple classes directly.\n",
        "\n",
        " - Uses the Softmax function to compute probabilities for each class:\n",
        "\n",
        "ùëÉ\n",
        "(\n",
        "ùë¶\n",
        "=\n",
        "ùëò\n",
        "‚à£\n",
        "ùë•\n",
        ")\n",
        "=\n",
        "ùëí\n",
        "ùúÉ\n",
        "ùëò\n",
        "ùë•\n",
        "‚àë\n",
        "ùëó\n",
        "=\n",
        "1\n",
        "ùêæ\n",
        "ùëí\n",
        "ùúÉ\n",
        "ùëó\n",
        "ùë•\n",
        " - The model assigns a probability to each class, and the class with the highest probability is selected.\n",
        "\n",
        " - Requires cross-entropy loss instead of binary log loss."
      ],
      "metadata": {
        "id": "htPhM7qntJtk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16. What are the advantages and disadvantages of Logistic Regression?\n",
        " - **Advantages of Logistic Regression:**\n",
        " 1. **Simple & Interpretable**\n",
        " 2. **Efficient & Fast**\n",
        " 3. **Probabilistic Predictions**\n",
        " 4. **Handles Multiclass Problems**\n",
        " 5. **Feature Importance**\n",
        " 6. **Less Prone to Overfitting**\n",
        "\n",
        " - **Disadvantages of Logistic Regression:**\n",
        " 1. **Assumes Linearity**\n",
        " 2. **Sensitive to Outliers**\n",
        " 3. **Not ideal for Complex Data**\n",
        " 4. **Requires Large Sample Size**\n",
        " 5. **Multicollinearity Issues**\n",
        " 6. **Limited to Binary or Categorical Outcomes**"
      ],
      "metadata": {
        "id": "rcjbGjoKtvPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#17. What are some use cases of Logistic Regression?\n",
        " - Logistic Regression is widely used across various domains for classification tasks. Here are some key use cases:     \n",
        "1. **Healthcare & Medical Diagnosis**\n",
        "2. **Finance & Banking**\n",
        "3. **Marketing & Customer Analytics**\n",
        "4. **Social Sciences & HR Analytics**\n",
        "5. **Manufacturing & Quality Control**\n",
        "6. **Security & Law Enforcement**"
      ],
      "metadata": {
        "id": "1CSPZClevYfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#18. What is the difference between Softmax Regression and Logistic Regression?\n",
        " - Softmax Regression and Logistic Regression are closely related, but they serve different purposes in classification tasks:\n",
        "\n",
        "**Key Differences**        \n",
        "1. **Number of Classes**\n",
        "\n",
        " - Logistic Regression is used for binary classification (two classes: 0 or 1).\n",
        " - Softmax Regression is used for multiclass classification (more than two classes).\n",
        "\n",
        "2. **Activation Function**\n",
        "\n",
        " - Logistic Regression uses the sigmoid function, which outputs probabilities between 0 and 1.\n",
        " - Softmax Regression uses the softmax function, which assigns probabilities to multiple classes, ensuring they sum to 1.\n",
        "\n",
        "3. **Decision Rule**\n",
        "\n",
        " - Logistic Regression applies a threshold (e.g., 0.5) to classify inputs into one of two categories.\n",
        " - Softmax Regression selects the class with the highest probability among multiple options.\n",
        "\n",
        "4. **Loss Function**\n",
        "\n",
        " - Logistic Regression uses binary cross-entropy loss for two-class problems.\n",
        " - Softmax Regression uses categorical cross-entropy loss, which considers multiple classes."
      ],
      "metadata": {
        "id": "l7aDPv9QwWdw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        " - One-vs-Rest(OVR) and Softmax(Multinomial Logistic Regression) depends on various factors, including dataset size, interpretability, and computational efficiency.          \n",
        "**One-vs-Rest(OVR) Approach:**             \n",
        "   - Each class is treated as a seperate binary classification problem. if you have K classes, you train K seperate logistic regression models, where each model predicts whether a sample belongs to a particular class or not.\n",
        "\n",
        "**Softmax(Multinomial Logistic Regression) Approach:**     \n",
        "\n",
        "   - Instead of training multiple classifiers, a single model learns to predict probabilities for all classes using the Softmax Function:       \n",
        "    ùëÉ\n",
        "(\n",
        "ùë¶\n",
        "=\n",
        "ùëò\n",
        "‚à£\n",
        "ùë•\n",
        ")\n",
        "=\n",
        "ùëí\n",
        "ùúÉ\n",
        "ùëò\n",
        "‚ãÖ\n",
        "ùë•\n",
        "‚àë\n",
        "ùëó\n",
        "=\n",
        "1\n",
        "ùêæ\n",
        "ùëí\n",
        "ùúÉ\n",
        "ùëó\n",
        "‚ãÖ\n",
        "ùë•"
      ],
      "metadata": {
        "id": "vGZ9L52VxJII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#20. How do we interpret coefficients in Logistic Regression?\n",
        " - the coefficients represent the impact of each feature on the log-odds of the target class occurring.     \n",
        " Here's how we interpret them:\n",
        " 1. **Understanding the Log-Odds Interpretation**\n",
        " 2. **Converting to Odds Ratio**\n",
        " 3. **Example Interpretation**\n",
        " 4. **Important Consideration**"
      ],
      "metadata": {
        "id": "-ij9Y2ULxha9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Practical Questions:**"
      ],
      "metadata": {
        "id": "2mr5mfWQGk5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy."
      ],
      "metadata": {
        "id": "1Sug8EdpGqod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azcq58nvG4kQ",
        "outputId": "9915c9fb-ae30-4e15-a012-219a8c3542e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy."
      ],
      "metadata": {
        "id": "pZQhWnskGw2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with L1 Regularization: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA8A2grbHIVa",
        "outputId": "e5e412b6-f77a-446b-a933-de4ce0087706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients."
      ],
      "metadata": {
        "id": "-9RjYX-0HTrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with L2 Regularization: {accuracy:.2f}\")\n",
        "\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGGbLW_DHhUJ",
        "outputId": "fdc39d57-5bac-4e7a-dc50-eb0e42ea96d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 Regularization: 1.00\n",
            "Model Coefficients:\n",
            "[[-0.39345607  0.96251768 -2.37512436 -0.99874594]\n",
            " [ 0.50843279 -0.25482714 -0.21301129 -0.77574766]\n",
            " [-0.11497673 -0.70769055  2.58813565  1.7744936 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')."
      ],
      "metadata": {
        "id": "cmHjko8WHe10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with Elastic Net Regularization: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNGxFkvgHSKF",
        "outputId": "dd3f55d1-88dc-4823-ee84-449f8db0445d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net Regularization: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'."
      ],
      "metadata": {
        "id": "yWII8CN0JJAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with One-vs-Rest: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akJRkKqvJQ3V",
        "outputId": "98f2bd33-b672-4797-8a21-ae9f82eb7ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with One-vs-Rest: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "yi-sGHhoJ1vN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "model = GridSearchCV(LogisticRegression(solver='liblinear', max_iter=200), param_grid, cv=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "best_params = model.best_params_\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with Best Parameters: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRfbTHW3J-lW",
        "outputId": "657fb88f-7b34-40cf-f6dd-2eec34c9824d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1'}\n",
            "Model Accuracy with Best Parameters: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7.Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy."
      ],
      "metadata": {
        "id": "KWcix2siJ-A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
        "\n",
        "print(f\"Average Accuracy with Stratified K-Fold: {scores.mean():.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPsKSXUlKaOt",
        "outputId": "e8f6f421-c34b-4b41-f52b-2fc4f32e11b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy with Stratified K-Fold: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8.Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."
      ],
      "metadata": {
        "id": "xp-pynhIKnA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def generate_dataset():\n",
        "    X, y = make_classification(\n",
        "        n_samples=1000,\n",
        "        n_features=10,\n",
        "        n_informative=5,\n",
        "        n_redundant=2,\n",
        "        n_classes=2,\n",
        "        random_state=42\n",
        "    )\n",
        "    return pd.DataFrame(X), pd.Series(y)\n",
        "\n",
        "def prepare_data(X, y):\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def train_model(X_train, y_train):\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    predictions = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "def main():\n",
        "    X, y = generate_dataset()\n",
        "    X_train, X_test, y_train, y_test = prepare_data(X, y)\n",
        "    model = train_model(X_train, y_train)\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "DN4zfd6rKsSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7f1166-393d-468d-92e4-5d3ac2e99c15"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9.Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "Yx_XVge-i-CU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 7),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "model = RandomizedSearchCV(LogisticRegression(max_iter=200), param_distributions=param_dist, cv=5, n_iter=10, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "best_params = model.best_params_\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Model Accuracy with Best Parameters: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qARuqtfTjqLu",
        "outputId": "b97a9f41-1bb5-45a9-f8c3-f59f08ef575f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'saga', 'penalty': 'l1', 'C': np.float64(1.0)}\n",
            "Model Accuracy with Best Parameters: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy."
      ],
      "metadata": {
        "id": "pWH-x8tajD5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = OneVsOneClassifier(LogisticRegression(max_iter=200))\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy with One-vs-One Multiclass Logistic Regression: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3mY55XYjpeF",
        "outputId": "0d56cd60-3fb8-4435-fdc0-b64bd963cb1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with One-vs-One Multiclass Logistic Regression: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11.Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification."
      ],
      "metadata": {
        "id": "hsLK0jz7jIG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "he-R5TfpjpIA",
        "outputId": "755a09c8-557a-4f22-fb2c-a626e7afb765"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.83\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score."
      ],
      "metadata": {
        "id": "LtyI0c2SjNg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0SKDhFZjohr",
        "outputId": "15fe5644-6b9c-439f-cc3d-395f6b015622"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.87\n",
            "Recall: 0.82\n",
            "F1-Score: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13.Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance."
      ],
      "metadata": {
        "id": "o1Z1EPPxjTHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBra4l9TjnXM",
        "outputId": "b3d8035c-54c0-45ad-952e-b40c6328b3d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.86\n",
            "Precision: 0.48\n",
            "Recall: 0.88\n",
            "F1-Score: 0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14.Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance."
      ],
      "metadata": {
        "id": "QivbTDWpjbH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
        "df = df[features + [\"Survived\"]]\n",
        "\n",
        "df[\"Age\"].fillna(df[\"Age\"].median(), inplace=True)\n",
        "df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0], inplace=True)\n",
        "\n",
        "df[\"Sex\"] = LabelEncoder().fit_transform(df[\"Sex\"])\n",
        "df[\"Embarked\"] = LabelEncoder().fit_transform(df[\"Embarked\"])\n",
        "\n",
        "X = df.drop(\"Survived\", axis=1)\n",
        "y = df[\"Survived\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4bERJg4jm8L",
        "outputId": "f202615c-1cae-4fa5-980d-ec47991c8d92"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.80\n",
            "Precision: 0.78\n",
            "Recall: 0.73\n",
            "F1-Score: 0.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-3da5375bda41>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Age\"].fillna(df[\"Age\"].median(), inplace=True)\n",
            "<ipython-input-9-3da5375bda41>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15.Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling."
      ],
      "metadata": {
        "id": "vT6oMcOTjg9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_no_scaling = LogisticRegression()\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy without Scaling: {accuracy_no_scaling:.2f}\")\n",
        "print(f\"Accuracy with Standardization: {accuracy_scaled:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTHSCLrojmRJ",
        "outputId": "a466005e-dab1-4f3d-ce54-bb106fba8c8b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without Scaling: 0.83\n",
            "Accuracy with Standardization: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16.Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score."
      ],
      "metadata": {
        "id": "ow4we0g9l2Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "5RY-W7ZFmbb0",
        "outputId": "5ab9e764-c4cd-40ec-f887-a2d265447025"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.91\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#17.Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy."
      ],
      "metadata": {
        "id": "9oNSZ7Wjl33n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(C=0.5, max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with C=0.5: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6oqR2APmoXn",
        "outputId": "deb3bdf0-37f0-4fdf-bf30-2f4c1f1326ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with C=0.5: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#18.Write a Python program to train Logistic Regression and identify important features based on model coefficients."
      ],
      "metadata": {
        "id": "VCBYU4W1l9IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "feature_importance = model.coef_[0]\n",
        "\n",
        "feature_names = [f'Feature {i+1}' for i in range(X.shape[1])]\n",
        "important_features = sorted(zip(feature_names, feature_importance), key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "print(\"Feature Importance Ranking (Higher absolute value indicates more importance):\")\n",
        "for feature, importance in important_features:\n",
        "    print(f\"{feature}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWXS70d6mxsu",
        "outputId": "2a3e14fe-b6ec-4e4a-c4e5-d74b0a0d61a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Ranking (Higher absolute value indicates more importance):\n",
            "Feature 7: 1.6204\n",
            "Feature 3: -0.7451\n",
            "Feature 9: -0.6290\n",
            "Feature 1: -0.4522\n",
            "Feature 6: -0.2288\n",
            "Feature 2: 0.1612\n",
            "Feature 10: 0.1025\n",
            "Feature 4: 0.0555\n",
            "Feature 5: -0.0432\n",
            "Feature 8: -0.0033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#19.Write a Python program to train Logistic Regression and evaluate its performance using Cohen‚Äôs Kappa Score."
      ],
      "metadata": {
        "id": "eHbYrx-amB7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen‚Äôs Kappa Score: {kappa_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSm0grUcm_b3",
        "outputId": "a561f003-4575-4825-d476-ed6a3a8cdc0e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen‚Äôs Kappa Score: 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#20.Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification."
      ],
      "metadata": {
        "id": "rAwiuvCRmGJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(recall, precision, label=f'PR Curve (AUC = {pr_auc:.2f})', color='purple')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "MP9uPMYmnIgB",
        "outputId": "bac2d1f0-a97c-4e35-945d-3eb72d822e3a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy."
      ],
      "metadata": {
        "id": "kVH4_qnRnR-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "accuracies = {}\n",
        "\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=200)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies[solver] = accuracy\n",
        "\n",
        "for solver, acc in accuracies.items():\n",
        "    print(f\"Accuracy with {solver} solver: {acc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmCU0s1MnREE",
        "outputId": "2383ca08-3b60-44bb-8287-ba753c8e282b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with liblinear solver: 0.83\n",
            "Accuracy with saga solver: 0.83\n",
            "Accuracy with lbfgs solver: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#22.Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)."
      ],
      "metadata": {
        "id": "iHDbQ3IinWzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mcc_score = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYDrS401oRwT",
        "outputId": "18a7a16f-5f6e-4891-9092-cfce1047d5ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling."
      ],
      "metadata": {
        "id": "oDGBRGzDncEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_raw = LogisticRegression()\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy on Raw Data: {accuracy_raw:.2f}\")\n",
        "print(f\"Accuracy on Standardized Data: {accuracy_scaled:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK3XLFv6oGMn",
        "outputId": "9996a7de-ba06-4cfc-86df-d990fa5a2ae8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Raw Data: 0.83\n",
            "Accuracy on Standardized Data: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation."
      ],
      "metadata": {
        "id": "aXk1OnUlnhFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {'C': np.logspace(-3, 3, 7)}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_C = grid_search.best_params_['C']\n",
        "y_pred = grid_search.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Optimal C Value: {best_C}\")\n",
        "print(f\"Model Accuracy with Optimal C: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdJ5EUJ7n4kv",
        "outputId": "1698ea82-cc52-4531-d4b4-09e269acebe6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C Value: 0.01\n",
            "Model Accuracy with Optimal C: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions."
      ],
      "metadata": {
        "id": "TWIXiBpLnl9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "joblib.dump(model, \"logistic_model.pkl\")\n",
        "print(\"Model saved successfully!\")\n",
        "\n",
        "loaded_model = joblib.load(\"logistic_model.pkl\")\n",
        "\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy after loading: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5G_S4isnp2G",
        "outputId": "8f8ef7a8-b298-4b68-f943-f9749f4f08b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n",
            "Model Accuracy after loading: 0.83\n"
          ]
        }
      ]
    }
  ]
}